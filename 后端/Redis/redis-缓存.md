# ## Redis 缓存



### 设置过期时间、释放资源

使用 Redis 做 `K-V` 存储，一定要注意过期时间的把控，任何 `K-V` 的存储都要设置过期时间，不管多长时间。一般在封装 Redis 操作工具类时提供默认使用系统公共超时时间的操作 API，避免新手在使用时不设置过期时间，导致内存的浪费。另外，通过连接池 `Jedis jedis = JedisPool.getResource(); ` 这样获取 Redis 连接最好使用 `try/finally` 块，并且在 `finally` 块中调用 `jedis.close();` 将连接归还给连接池，否则将会一直持有连接，很有可能导致在将来的某一时刻报拿不到连接的错。这也是之前某一个同事犯过的错导致生产 bug！

### 缓存穿透

是针对数据库和缓存中都没有的数据。你以为 Redis 做缓存就万无一失吗？就单纯的遵循那种经典操作吗？（即：请求来了，先看缓存有没有，有直接返回，没有就查数据库，数据库有的话先存缓存，然后返回，数据库没有就返回空）这样就是 Redis 缓存的正确姿势吗？如果你这样做，很可能疏忽一点，那就是缓存穿透。如之前在项目中做的一个需求-页面广告可配置化自动上下线（我在之前专门写过一篇文章介绍这个需求的一步步演进过程，对 Redis 新手很有帮助，感兴趣的可以去看看），简单的提一下吧，就是比如在支付完成的页面大家都应该见过吧，比如支付完成后的结果页，可能会弹出来一个红包什么的，页面下方的广告位等，就是类似的这样一个需求。因为这个页面访问量很大，进这个页面就查这个广告位的数据，当运营最近不想配置广告了，这边查到的是不是就是是空啊？数据库也是空的，缓存也没有数据，那很多请求都来，这样就平白无故的造成了数据库的压力呀，多么的浪费！如果是别的其他业务，黑客钻了空子，专门请求你系统根本不存在的数据，请求多了，都打到数据库，是很有可能把你数据库打死的。如果你在做需求的时候没想到这一点，那后续出了问题，你就等着背锅了。

怎么避免呢？

好办，可以将数据库也不存在的数据存个 `null` 值或一个空` json`（总之你自己约定好就行），也给放到 Redis 里，设置个较短的过期时间，下次再来取的时候看到是空就直接返回。另外，可以使用布隆过滤器做一层系统级的防护，专门去拦截系统中根本不存在的 `key`。

### 缓存雪崩

是指大量 `Key` 同时失效，对这些 `Key` 的请求又会打到 `DB` 上。比如你将用户数据放到缓存里，当某一时刻这些数据全部都过期了，大量请求都过来，发现缓存无法命中，不就都去数据库了吗，数据库一下子来这么多请求不就搞挂了吗？解决办法就是尽量是 `key` 的过期时间分散开，不要集中。在一个固定的过期时间上+一个随机值，比如你设置的过期时间是5小时，你可以加一个0-600秒的随机值。

### 缓存击穿

是针对缓存中没有但数据库有的数据。假如某功能在前期宣传力度比较大，或预计该功能上线后点击量比较大的话，那么在功能上线后很可能就会一瞬间大量用户来点击这个功能，因为逻辑是首次进入该功能的用户展示协议页，我们的后台处理虽然加了 Redis 缓存，但是新上的功能所有用户都没有点过，那么 Redis 里就没有缓存，是不是所有用户的请求都落到数据库了？一旦瞬间流量非常大，数据库安全性就存在隐患，有被搞垮的可能。

解决的办法是可以在该功能上线前，提前将需要做缓存的数据放入 Redis，即**缓存预热**。将所有用户的信息都放到Redis。

所以为避免流量集中落到数据库，另一种思路，此时我们可以使用消息队列 `MQ`。将插入操作的请求发往消息队列，使插入操作以一定的速率到数据库执行，使得对数据库的请求数尽量平滑，消息发给消息队列立即返回给前端成功，不用等待插库完成，用 `MQ` 实现了异步解耦，削峰填谷。

### 缓存并发

缓存失效时多个请求同时请求同一个 `key`，都发现缓存中空了，都去查数据库，这不是浪费吗，正常一个去查就行了，查完放缓存别的请求直接从缓存拿就行了。这就是缓存并发问题。当请求非常的多的时候，会对数据库造成很大的冲击，也是有可能把数据库搞挂的吧？怎么解决，可以对更新缓存的操作加锁，使用 `synchronized` 吗？不行，因为生产上是分布式部署的，需要使用 redis 分布式锁。

例如，当缓存数据失效的时候，某一线程使用资源 ID 作为 `key` 尝试加分布式锁，加锁成功的线程执行更新缓存的操作将查到的数据放入缓存缓存中，其他线程就可以直接使用缓存数据了。

### 热点 `Key` 问题

针对热点数据，我们可以设置热点 `Key` 的过期时间很大，或者在逻辑上永不过期。啥意思呢？

意思就是说，假如我们设置热点数据过期时间为24小时，那么我们可以使用监听器去监听这热点数据，当检测到它快要过期时，异步起个线程去更新这个热点数据。可以达到逻辑上永不过期的效果。

另外一点，我们要有热点数据自动检测机制。即有个监控平台，来监控每个 `key` 某个时间段的请求次数，过期次数，查库次数，来分析这个 `key` 是不是热点数据，当达到某阈值时将 `key` 升级为热点 `key`，然后走热点数据的逻辑。

### 分布式锁

正如上面所说，在集群部署的情况下 `synchronized` 就失效了，所以分布式锁就派上用场了。常见的分布式锁的实现方式有三种：基于数据库，基于 Redis，基于 Zookeeper。

Redis 分布式锁需要特别注意的点就是锁的过期时间，如，使用 `redis` 的 `setnx` 命令，设置成功即表示拿到锁，然后设置过期时间，命令执行失败的线程表示获取锁失败。一定要注意锁的过期时间的设置，有加锁的操作，也要有解锁的操作。如之前我们项目的一个临时性的一个组团竞走的活动，10人成团竞走PK的活动，在组团阶段，用户可以邀请朋友加入自己的团。我们的团数据是存放在 Redis 中的，包括每个团的人数。当用户发起入团操作时，后台逻辑会从 redis 取该团的现有成员数，如果小于10才能继续走下面的逻辑。当并发场景下，如团长分享给很多人入团邀请，这些人的入团请求并发执行的情况下很有可能能造成组团人数超过10人的情况。因为在并发场景下，执行获取当前团成员数的这行代码会被多个请求获取到，比如临界的时候，团成员已经有了9个，同时来了俩入团请求，如果不加控制，同时执行读取现有团成员个数时都读到的是9，然后都执行入团操作，就会造成团成员超过10人的 bug。

所以在入团请求的逻辑上，要加分布式锁，获取到锁才能执行后续逻辑。因为获取锁的操作是使用 `setnx` 命令，并没有等待锁的机制，我们需要在获取锁的逻辑加一个自旋，每隔一定时间尝试一次获取，超过一定时间后返回加锁失败。

另外，还需要遵循“解铃还须系铃人”的原则，谁加的锁谁解，不然自己加的锁，被别人解了也是会造成问题的。例如，用户A，请求入团，拿到分布式锁，如果A因为某些原因在锁超时时间内没有执行完代码，锁就过期自动释放了，如果此时B请求加入同一个团，拿到了分布式锁，如果此时A请求执行完了，释放锁了，但是释放的是B的锁，这样也有可能造成团人数超过10的bug。所以，设置分布式锁时的value可以设置成不同的值，如A请求是用户ID为12的用户，设置分布式锁的时候就value就可以用这个唯一的元素，当解锁的时候再验证value是12时才能执行解锁操作。

还有一种场景需要考虑。当 Redis `master` 发生故障，主备切换时往往会造成数据丢失，包括分布式锁的 `Key-Value`。这样就会导致锁间接的被释放了，假如操作还没执行完，锁被其他请求拿到了，分布式锁就起不到作用了。

考虑到这方面的问题，Redis 官方提供了 `Redlock` 算法，以及相应的开源实现 `Redisson`。用到分布式锁的场景，大家可以直接使用 `Redisson`，非常方便，后期可能会写一写 `Redisson` 的技术干货。

另外，如果系统对可靠性要求很高，如需用到分布式锁，建议使用分布式锁的另外实现方式，如：Zookeeper，etcd等。

